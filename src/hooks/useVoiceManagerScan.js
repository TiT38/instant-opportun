import { useEffect, useRef } from 'react';
import { useAppStore } from '../store/appStore';

// Syst√®me vocal optimis√© pour le scan corporel avec 18 s√©quences
export const useVoiceManagerScan = () => {
  const { voiceSettings, currentSession, isSessionActive } = useAppStore();
  const scheduledTimeoutsRef = useRef([]);
  const currentAudioRef = useRef(null);
  const isPlayingRef = useRef(false);

  // Chemin des fichiers audio pour le scan corporel
  const getScanAudioPath = (filename) => {
    const gender = voiceSettings.gender; // 'female' ou 'male'
    return `/audio/scan-corporel/${gender}/${filename}.mp3`;
  };

  // MAPPING DES FICHIERS SCAN CORPOREL - 18 S√âQUENCES
  const SCAN_AUDIO_FILES = {
    welcome: 'welcome',
    head: 'head',
    face: 'face',
    neck: 'neck',
    chest: 'chest',
    back: 'back',
    abdomen: 'abdomen',
    hips: 'hips',
    thighs: 'thighs',
    knees: 'knees',
    calves: 'calves',
    ankles: 'ankles',
    feet: 'feet',
    wholebody: 'wholebody',
    breathing: 'breathing',
    awareness: 'awareness',
    presence: 'presence',
    completion: 'completion'
  };

  // Fonction pour v√©rifier si un fichier audio existe
  const checkAudioFileExists = async (audioPath) => {
    try {
      console.log(`üîç V√©rification fichier: ${audioPath}`);
      const response = await fetch(audioPath, { 
        method: 'HEAD',
        cache: 'no-cache'
      });
      const exists = response.ok;
      console.log(`${exists ? '‚úÖ' : '‚ùå'} Fichier ${audioPath}: ${response.status}`);
      return exists;
    } catch (error) {
      console.log(`‚ùå Erreur v√©rification ${audioPath}:`, error.message);
      return false;
    }
  };

  // Fonction pour jouer un fichier audio local AVEC V√âRIFICATION PR√âALABLE
  const playLocalAudio = async (audioPath) => {
    // V√©rifier qu'aucun audio n'est en cours
    if (isPlayingRef.current) {
      console.log(`‚è∏Ô∏è Audio en cours, attente pour: ${audioPath}`);
      return new Promise(resolve => {
        const checkInterval = setInterval(() => {
          if (!isPlayingRef.current) {
            clearInterval(checkInterval);
            playLocalAudio(audioPath).then(resolve);
          }
        }, 100);
      });
    }
    
    // V√âRIFICATION PR√âALABLE DU FICHIER
    const fileExists = await checkAudioFileExists(audioPath);
    if (!fileExists) {
      console.log(`‚ùå Fichier non trouv√©: ${audioPath} - Fallback imm√©diat`);
      throw new Error(`Fichier non trouv√©: ${audioPath}`);
    }
    
    return new Promise((resolve, reject) => {
      console.log(`üéµ Lecture audio: ${audioPath}`);
      
      const audio = new Audio();
      audio.volume = voiceSettings.volume;
      audio.preload = 'auto';
      currentAudioRef.current = audio;
      isPlayingRef.current = true;

      // Timeout de s√©curit√©
      const timeout = setTimeout(() => {
        console.log(`‚è∞ Timeout lecture: ${audioPath} - Fallback`);
        isPlayingRef.current = false;
        audio.src = '';
        reject(new Error(`Timeout lecture: ${audioPath}`));
      }, 3000);

      audio.oncanplaythrough = () => {
        console.log(`‚úÖ Audio pr√™t: ${audioPath}`);
        clearTimeout(timeout);
      };

      audio.onended = () => {
        clearTimeout(timeout);
        currentAudioRef.current = null;
        isPlayingRef.current = false;
        console.log(`‚úÖ Audio termin√©: ${audioPath}`);
        resolve();
      };

      audio.onerror = (e) => {
        clearTimeout(timeout);
        currentAudioRef.current = null;
        isPlayingRef.current = false;
        console.log(`‚ùå ERREUR AUDIO PREMIUM: ${audioPath}`, e);
        reject(new Error(`Erreur lecture: ${audioPath}`));
      };

      audio.onloadstart = () => {
        console.log(`üîÑ Chargement audio: ${audioPath}`);
      };

      // D√©finir la source et tenter la lecture
      audio.src = audioPath;
      
      audio.load(); // Forcer le chargement
      
      audio.play().then(() => {
        clearTimeout(timeout);
        console.log(`üîä Lecture d√©marr√©e: ${audioPath}`);
      }).catch((playError) => {
        clearTimeout(timeout);
        isPlayingRef.current = false;
        console.log(`‚ùå ERREUR PLAY PREMIUM: ${audioPath}`, playError.message);
        reject(playError);
      });
    });
  };

  // Fonction pour synth√®se vocale (fallback)
  const speakWithSystemVoice = (text) => {
    // V√©rifier qu'aucun audio n'est en cours
    if (isPlayingRef.current) {
      console.log(`‚è∏Ô∏è Audio en cours, attente pour synth√®se: "${text}"`);
      return new Promise(resolve => {
        const checkInterval = setInterval(() => {
          if (!isPlayingRef.current) {
            clearInterval(checkInterval);
            speakWithSystemVoice(text).then(resolve);
          }
        }, 100);
      });
    }

    return new Promise((resolve, reject) => {
      if (!window.speechSynthesis) {
        console.error('‚ùå Speech Synthesis non support√©');
        reject(new Error('Speech Synthesis non support√©'));
        return;
      }

      console.log(`üó£Ô∏è Synth√®se vocale: "${text}"`);
      
      // Arr√™ter toute synth√®se en cours
      speechSynthesis.cancel();
      isPlayingRef.current = true;
      
      setTimeout(() => {
        const utterance = new SpeechSynthesisUtterance(text);

        // Param√®tres optimis√©s pour la relaxation
        utterance.rate = 0.8;  // D√©bit lent et apaisant
        utterance.pitch = voiceSettings.gender === 'male' ? 0.8 : 1.1;
        utterance.volume = voiceSettings.volume;
        utterance.lang = 'fr-FR';

        // S√©lectionner la meilleure voix fran√ßaise
        const voices = speechSynthesis.getVoices();
        const frenchVoices = voices.filter(v => v.lang.startsWith('fr'));
        
        if (frenchVoices.length > 0) {
          const preferredVoices = voiceSettings.gender === 'female' 
            ? ['Am√©lie', 'Marie', 'Audrey', 'Google fran√ßais', 'Samantha']
            : ['Thomas', 'Nicolas', 'Google fran√ßais', 'Alex'];
          
          let selectedVoice = null;
          for (const preferred of preferredVoices) {
            selectedVoice = frenchVoices.find(v => v.name.includes(preferred));
            if (selectedVoice) break;
          }
          
          utterance.voice = selectedVoice || frenchVoices[0];
          console.log(`üé§ Voix: ${utterance.voice.name}`);
        }

        utterance.onstart = () => {
          console.log(`üîä Synth√®se d√©marr√©e: "${text}"`);
        };

        utterance.onend = () => {
          isPlayingRef.current = false;
          console.log(`‚úÖ Synth√®se termin√©e: "${text}"`);
          resolve();
        };

        utterance.onerror = (event) => {
          isPlayingRef.current = false;
          console.log(`‚ö†Ô∏è Erreur synth√®se: "${text}":`, event.error);
          resolve(); // R√©soudre quand m√™me pour ne pas bloquer
        };

        speechSynthesis.speak(utterance);
      }, 200);
    });
  };

  // TEXTES EXACTS DE FALLBACK POUR LE SCAN CORPOREL - 18 S√âQUENCES
  const SCAN_FALLBACK_TEXTS = {
    welcome: "Bienvenue dans cette s√©ance de scan corporel. Installez-vous confortablement, fermez les yeux si vous le souhaitez. Nous allons explorer chaque partie de votre corps pour une relaxation profonde.",
    head: "Portez votre attention sur le sommet de votre t√™te. Sentez cette zone se d√©tendre compl√®tement. Laissez toute tension se dissoudre.",
    face: "Descendez vers votre visage. Rel√¢chez votre front, vos sourcils, vos paupi√®res. D√©tendez vos m√¢choires, votre langue, votre gorge. Laissez votre visage s'adoucir.",
    neck: "Votre cou et vos √©paules se rel√¢chent maintenant. Laissez partir toute tension accumul√©e dans cette zone. Sentez un agr√©able rel√¢chement.",
    chest: "Votre poitrine s'ouvre et se d√©tend √† chaque respiration. Sentez l'air qui entre et qui sort librement. Accueillez cette sensation d'espace.",
    back: "Votre dos se d√©tend vert√®bre par vert√®bre, du haut vers le bas. Chaque vert√®bre s'aligne parfaitement. Sentez le support sous votre dos.",
    abdomen: "Votre ventre se gonfle et se d√©gonfle naturellement, sans effort. Sentez une douce chaleur s'y r√©pandre. Laissez votre respiration se faire librement.",
    hips: "Vos hanches et votre bassin se rel√¢chent compl√®tement. Sentez le poids de votre corps s'enfoncer dans le support. Laissez aller toute tension.",
    thighs: "Vos cuisses se d√©tendent profond√©ment. Sentez les muscles se rel√¢cher, devenir lourds et confortables. Toute tension s'√©vapore.",
    knees: "Vos genoux se d√©tendent. Sentez l'espace dans vos articulations. Laissez-les se rel√¢cher compl√®tement.",
    calves: "Vos mollets se rel√¢chent enti√®rement. Sentez l'√©nergie circuler librement. Chaque fibre musculaire se d√©tend.",
    ankles: "Vos chevilles se d√©tendent. Sentez l'espace dans ces articulations. Laissez toute tension se dissoudre.",
    feet: "Vos pieds, jusqu'au bout de vos orteils, sont maintenant compl√®tement d√©tendus et lourds. Sentez la chaleur et le rel√¢chement dans cette zone.",
    wholebody: "Une vague de bien-√™tre parcourt maintenant tout votre corps, de la t√™te aux pieds. Vous √™tes dans un √©tat de relaxation profonde. Savourez cette sensation d'unit√©.",
    breathing: "Observez votre respiration, calme et r√©guli√®re. Chaque inspiration vous apporte √©nergie et vitalit√©. Chaque expiration approfondit votre relaxation.",
    awareness: "Prenez conscience de votre corps dans son ensemble, parfaitement d√©tendu et en harmonie. Ressentez cette pr√©sence paisible qui vous habite.",
    presence: "Restez dans cet √©tat de relaxation profonde, en pleine conscience de votre corps et de votre respiration. Savourez ce moment de paix int√©rieure.",
    completion: "Progressivement, reprenez conscience de votre environnement. Bougez doucement vos doigts, vos orteils. √âtirez-vous si vous le souhaitez. Votre corps est maintenant compl√®tement d√©tendu et votre esprit apais√©."
  };

  // Fonction pour jouer un audio SCAN CORPOREL avec fallback
  const playScanAudio = async (audioKey) => {
    console.log(`üßò Scan Corporel Audio: ${audioKey}`);
    
    try {
      // Essayer d'abord le fichier audio enregistr√©
      const audioPath = getScanAudioPath(audioKey);
      await playLocalAudio(audioPath);
      console.log(`‚úÖ Fichier audio lu: ${audioKey}`);
    } catch (error) {
      // Fallback vers synth√®se vocale
      console.log(`üîÑ Fallback synth√®se pour: ${audioKey} (${error.message})`);
      const fallbackText = SCAN_FALLBACK_TEXTS[audioKey];
      if (fallbackText) {
        try {
          await speakWithSystemVoice(fallbackText);
          console.log(`‚úÖ Fallback r√©ussi: ${audioKey}`);
        } catch (fallbackError) {
          console.error(`‚ùå Erreur fallback ${audioKey}:`, fallbackError);
        }
      }
    }
  };

  // Fonction principale pour parler
  const speak = (text) => {
    if (!voiceSettings.enabled || !text.trim()) {
      console.log('üîá Voix d√©sactiv√©e');
      return Promise.resolve();
    }

    console.log(`üó£Ô∏è Parole: "${text}"`);
    return speakWithSystemVoice(text);
  };

  // SYST√àME VOCAL SCAN CORPOREL - 18 S√âQUENCES
  const startScanGuidance = () => {
    if (!voiceSettings.enabled) {
      console.log('üîá Guidage vocal d√©sactiv√©');
      return;
    }

    console.log(`üßò D√âMARRAGE SCAN CORPOREL - 18 S√âQUENCES (${voiceSettings.gender})`);
    
    // Nettoyer les anciens timeouts
    scheduledTimeoutsRef.current.forEach(timeout => clearTimeout(timeout));
    scheduledTimeoutsRef.current = [];
    
    // Timings pour le scan corporel - 18 s√©quences
    const scanTimings = [
      { time: 0, audioKey: 'welcome', description: 'Bienvenue dans cette s√©ance de scan corporel' },
      { time: 30, audioKey: 'head', description: 'T√™te' },
      { time: 60, audioKey: 'face', description: 'Visage' },
      { time: 90, audioKey: 'neck', description: 'Cou et √©paules' },
      { time: 120, audioKey: 'chest', description: 'Poitrine' },
      { time: 150, audioKey: 'back', description: 'Dos' },
      { time: 180, audioKey: 'abdomen', description: 'Ventre' },
      { time: 210, audioKey: 'hips', description: 'Hanches et bassin' },
      { time: 240, audioKey: 'thighs', description: 'Cuisses' },
      { time: 255, audioKey: 'knees', description: 'Genoux' },
      { time: 270, audioKey: 'calves', description: 'Mollets' },
      { time: 285, audioKey: 'ankles', description: 'Chevilles' },
      { time: 300, audioKey: 'feet', description: 'Pieds' },
      { time: 360, audioKey: 'wholebody', description: 'Corps entier' },
      { time: 420, audioKey: 'breathing', description: 'Respiration' },
      { time: 480, audioKey: 'awareness', description: 'Prise de conscience' },
      { time: 540, audioKey: 'presence', description: 'Pr√©sence' },
      { time: 570, audioKey: 'completion', description: 'Fin de s√©ance' }
    ];
    
    // Programmer les phases du scan corporel
    scanTimings.forEach(({ time, audioKey, description }) => {
      const timeout = setTimeout(() => {
        if (isSessionActive) {
          console.log(`üßò ${time}s: ${audioKey} - ${description}`);
          playScanAudio(audioKey);
        }
      }, time * 1000);
      scheduledTimeoutsRef.current.push(timeout);
    });
    
    console.log(`‚úÖ SCAN CORPOREL PROGRAMM√â - 18 S√âQUENCES SUR 10 MINUTES`);
  };

  // Arr√™ter tout
  const stop = () => {
    console.log('üõë Arr√™t syst√®me vocal scan corporel');
    
    // Annuler tous les timeouts
    scheduledTimeoutsRef.current.forEach(timeout => clearTimeout(timeout));
    scheduledTimeoutsRef.current = [];
    
    // Arr√™ter l'audio en cours
    if (currentAudioRef.current) {
      currentAudioRef.current.pause();
      currentAudioRef.current.src = '';
      currentAudioRef.current = null;
    }
    
    // Marquer comme non en cours
    isPlayingRef.current = false;
    
    // Arr√™ter la synth√®se
    try {
      speechSynthesis.cancel();
    } catch (error) {
      console.log('‚ö†Ô∏è Erreur arr√™t synth√®se:', error);
    }
  };

  // Test de disponibilit√© des fichiers audio pour le scan corporel
  const testScanAudioFiles = async () => {
    console.log('üîç Test des fichiers audio Scan Corporel...');
    const results = {};
    
    for (const [key, filename] of Object.entries(SCAN_AUDIO_FILES)) {
      const audioPath = getScanAudioPath(filename);
      const exists = await checkAudioFileExists(audioPath);
      results[key] = exists;
    }
    
    const availableCount = Object.values(results).filter(Boolean).length;
    console.log(`üìä Fichiers disponibles: ${availableCount}/${Object.keys(SCAN_AUDIO_FILES).length}`);
    
    return results;
  };

  // Initialisation
  useEffect(() => {
    console.log('üßò Syst√®me vocal scan corporel initialis√© - 18 S√âQUENCES');
    
    // Charger les voix syst√®me pour le fallback
    const initVoices = () => {
      const voices = speechSynthesis.getVoices();
      console.log(`üó£Ô∏è ${voices.length} voix syst√®me disponibles pour fallback`);
    };

    if (speechSynthesis.getVoices().length === 0) {
      speechSynthesis.addEventListener('voiceschanged', initVoices);
    } else {
      initVoices();
    }

    // Test initial des fichiers audio pour Scan Corporel
    if (currentSession === 'scan') {
      testScanAudioFiles();
    }

    return () => {
      stop();
      speechSynthesis.removeEventListener('voiceschanged', initVoices);
    };
  }, [currentSession]);

  return {
    speak,
    stop,
    isProcessing: isPlayingRef.current,
    startScanGuidance,
    playScanAudio,
    getScanAudioPath,
    SCAN_AUDIO_FILES,
    SCAN_FALLBACK_TEXTS,
    testScanAudioFiles,
    checkAudioFileExists,
  };
};